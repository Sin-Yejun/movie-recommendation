import openai
import json
import numpy as np
import faiss
from sklearn.metrics.pairwise import cosine_similarity
import os
import time

# âœ… í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸° (ë˜ëŠ” ì§ì ‘ í• ë‹¹ ê°€ëŠ¥)
openai.api_key = os.getenv("OPENAI_API_KEY")
# openai.api_key = "your-api-key"  # ì§ì ‘ ì…ë ¥ë„ ê°€ëŠ¥

# âœ… ê²½ë¡œ ì„¤ì •
MOVIE_PATH = 'src/db/movies.json'
EMBEDDING_PATH = 'src/cache/embeddings.npy'
INDEX_PATH = 'src/cache/faiss.index'

# âœ… 1. ì˜í™” ë°ì´í„° ë¡œë“œ
with open(MOVIE_PATH, 'r', encoding='utf-8') as f:
    movies = json.load(f)

# âœ… 2. ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ êµ¬ì„±
movie_texts = [
    f"{movie['ì œëª©']}. ì¥ë¥´: {movie['ì¥ë¥´']}. ì¶œì—°: {movie['ì¶œì—°ì§„']}. ì¤„ê±°ë¦¬: {movie['ì¤„ê±°ë¦¬']}"
    for movie in movies
]

# âœ… 3. OpenAI ì„ë² ë”© í•¨ìˆ˜
def get_embedding(text, model="text-embedding-3-small"):
    try:
        response = openai.embeddings.create(
            input=[text],
            model=model
        )
        return np.array(response.data[0].embedding, dtype=np.float32)
    except Exception as e:
        print(f"[âŒ] Embedding error: {e}")
        return None

# âœ… 4. ì„ë² ë”© ì „ì²´ ìƒì„±
def build_movie_embeddings(texts):
    embeddings = []
    for idx, text in enumerate(texts):
        print(f"[ğŸ”] Embedding {idx+1}/{len(texts)}: {movies[idx]['ì œëª©']}")
        emb = get_embedding(text)
        if emb is not None:
            embeddings.append(emb)
        else:
            embeddings.append(np.zeros(1536, dtype=np.float32))  # ì‹¤íŒ¨ ì‹œ 0ìœ¼ë¡œ ì±„ì›€
        time.sleep(0.5)  # API í˜¸ì¶œ ì†ë„ ì œí•œ ëŒ€ì‘
    return embeddings

# âœ… 5. ì €ì¥ í•¨ìˆ˜
def save_embeddings(embeddings, index):
    os.makedirs(os.path.dirname(EMBEDDING_PATH), exist_ok=True)
    np.save(EMBEDDING_PATH, np.array(embeddings))
    faiss.write_index(index, INDEX_PATH)
    print("[âœ…] ì„ë² ë”© ë° ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ")

# âœ… 6. ë¡œë“œ í•¨ìˆ˜
def load_embeddings():
    if os.path.exists(EMBEDDING_PATH) and os.path.exists(INDEX_PATH):
        print("[ğŸ“‚] ì €ì¥ëœ ì„ë² ë”©ê³¼ ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
        loaded_embeddings = np.load(EMBEDDING_PATH)
        loaded_index = faiss.read_index(INDEX_PATH)
        return loaded_embeddings, loaded_index
    return None, None

# âœ… 7. ë©”ì¸ íë¦„: ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
embeddings, index = load_embeddings()

if embeddings is None:
    print("[ğŸš€] ì„ë² ë”© ìƒì„± ì¤‘...")
    embeddings = build_movie_embeddings(movie_texts)
    
    embedding_dim = len(embeddings[0])
    index = faiss.IndexFlatL2(embedding_dim)
    index.add(np.array(embeddings))

    save_embeddings(embeddings, index)

# âœ… 8. ê²€ìƒ‰ í•¨ìˆ˜ (Re-ranking í¬í•¨)
def search_with_reranking(query, top_k=3):
    query_embedding = get_embedding(query).reshape(1, -1)
    distances, indices = index.search(query_embedding, top_k)
    candidate_indices = indices[0]

    candidate_embeddings = np.array([embeddings[i] for i in candidate_indices])
    sim_scores = cosine_similarity(query_embedding, candidate_embeddings)[0]
    reranked_indices = candidate_indices[np.argsort(-sim_scores)]

    return [movies[i] for i in reranked_indices]

# âœ… 9. ì‹¤í–‰ë¶€
if __name__ == "__main__":
    query = input("ğŸ¯ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    results = search_with_reranking(query, top_k=3)

    print("\nğŸ¬ ê²€ìƒ‰ ê²°ê³¼:")
    for i, movie in enumerate(results, 1):
        print(f"\n{i}. [{movie['ì œëª©']}]")
        print(f"ì¥ë¥´: {movie['ì¥ë¥´']}")
        print(f"ê´€ëŒê° í‰ì : {movie['ê´€ëŒê° í‰ì ']}")
        print(f"ì¶œì—°ì§„: {movie['ì¶œì—°ì§„']}")
        print(f"ì¤„ê±°ë¦¬: {movie['ì¤„ê±°ë¦¬']}...")
