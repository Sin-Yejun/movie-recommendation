from fastapi import FastAPI, Query, HTTPException
from pydantic import BaseModel
import faiss
import numpy as np
from openai import OpenAI
import json
import pandas as pd
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# ğŸ”¹ CORS ì„¤ì • ì¶”ê°€ (ë³´ì•ˆ ì„¤ì • ê°€ëŠ¥)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš© ê°€ëŠ¥ (ì˜ˆ: ["http://localhost:3000"])
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš© (GET, POST ë“±)
    allow_headers=["*"],
)

# OpenAI API í´ë¼ì´ì–¸íŠ¸
client = OpenAI()

# FAISS ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
index = faiss.read_index("db/movie_index.faiss")
movie_titles = np.load("db/movie_titles.npy")

# JSON ì˜í™” ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
with open("db/movies.json", "r", encoding="utf-8") as f:
    movies = json.load(f)

# CSV ë¦¬ë·° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("db/movie_reviews.csv", encoding="utf-8")


class QueryModel(BaseModel):
    query: str


def query_embedding(text):
    """ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )

    embedding = np.array(response.data[0].embedding, dtype=np.float32).reshape(1, -1)
    return embedding


def generate_ai_response(query, movie_data):
    """ChatGPT APIë¥¼ ì´ìš©í•´ ì˜í™” ì¶”ì²œ ë° ì •ë³´ ì œê³µ"""
    prompt = f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{query}"
    
    ì•„ë˜ ì˜í™” ë°ì´í„°ì™€ ë¦¬ë·°ë¥¼ ì°¸ê³ í•˜ì—¬, ê°€ì¥ ì ì ˆí•œ ë‹µë³€ì„ ë§Œë“¤ì–´ì¤˜.
    
    ì˜í™” ë°ì´í„°:
    {json.dumps(movie_data, ensure_ascii=False, indent=2)}

    ë‹µë³€ í˜•ì‹:
    - Markdown ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì—¬ì•¼ í•¨
    - í•„ìš”í•˜ë©´ **ë³¼ë“œì²´**, *ì´íƒ¤ë¦­ì²´*, ë¦¬ìŠ¤íŠ¸, ì œëª©ì„ í™œìš©
    - ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë‹µë³€ ì œê³µ
    - í•„ìš”í•˜ë©´ ì˜í™” 1~3ê°œ ì¶”ì²œ, ì¤„ê±°ë¦¬ ìš”ì•½, ë¦¬ë·° ìš”ì•½ ë“±ì„ í¬í•¨
    - ë‹µë³€ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content.strip()


@app.post("/chat")
async def search(query_data: QueryModel):
    query = query_data.query
    print(f"ì‚¬ìš©ì ì…ë ¥: {query}")

    try:
        # FAISS ê²€ìƒ‰ (ìƒìœ„ 5ê°œ ì˜í™” ì°¾ê¸°)
        embedding = query_embedding(query)
        distances, indices = index.search(embedding, 5)

        if len(indices[0]) == 0:
            raise HTTPException(status_code=404, detail="ê´€ë ¨ëœ ì˜í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì˜í™” ì •ë³´ ìˆ˜ì§‘
        relevant_movies = []
        for idx in indices[0]:
            if idx >= len(movies):  # ì¸ë±ìŠ¤ ë²”ìœ„ ì´ˆê³¼ ë°©ì§€
                continue
            movie_data = movies[idx].copy()  # ì›ë³¸ ë³€ê²½ ë°©ì§€
            movie_data.pop("ì˜í™”í¬ìŠ¤í„°", None)  # ğŸ”¹ 'ì˜í™”í¬ìŠ¤í„°' í‚¤ ì œê±°
            relevant_movies.append(movie_data)

        # AIê°€ ìµœì ì˜ ë‹µë³€ ìƒì„±
        response_text = generate_ai_response(query, relevant_movies)
        print(response_text)

        return {"response": response_text}

    except Exception as e:
        print("ì—ëŸ¬ ë°œìƒ:", str(e))
        raise HTTPException(status_code=500, detail="ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
