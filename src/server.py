from fastapi import FastAPI, Query, HTTPException
from pydantic import BaseModel
import faiss
import numpy as np
from openai import OpenAI
import json
import os
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import random

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# ğŸ”¹ CORS ì„¤ì • ì¶”ê°€ (ë³´ì•ˆ ì„¤ì • ê°€ëŠ¥)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI API í´ë¼ì´ì–¸íŠ¸
client = OpenAI()

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ğŸ”¹ FAISS ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
index = faiss.read_index(os.path.join(BASE_DIR, "db/movie_index.faiss"))

# ğŸ”¹ JSON ì˜í™” ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
with open(os.path.join(BASE_DIR, "db/movies.json"), "r", encoding="utf-8") as f:
    movies = json.load(f)

# ğŸ”¹ NumPy ë°°ì—´ë¡œ ì €ì¥ëœ ì˜í™” ë¦¬ë·° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
movie_reviews = np.load(os.path.join(BASE_DIR, "db/movie_reviews.npy"), allow_pickle=True)

class QueryModel(BaseModel):
    query: str

def query_embedding(text):
    """ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ OpenAI ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return np.array(response.data[0].embedding, dtype=np.float32).reshape(1, -1)

def get_movie_reviews(movie_title, max_reviews=5, max_length=300):
    """ì˜í™” ì œëª©ìœ¼ë¡œ ë¦¬ë·° ê°€ì ¸ì˜¤ê¸° (ì²­í‚¹ ì ìš© + í‰ì  ê· í˜• ìœ ì§€)"""
    reviews = movie_reviews[movie_reviews[:, 0] == movie_title]

    if len(reviews) == 0:
        return "ì´ ì˜í™”ì— ëŒ€í•œ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤."

    # ğŸ”¹ í‰ì  ê¸°ì¤€ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
    sorted_reviews = sorted(reviews, key=lambda x: float(x[2]), reverse=True)

    # ğŸ”¹ í‰ì  ê·¸ë£¹ ë‚˜ëˆ„ê¸°
    total_reviews = len(sorted_reviews)
    
    if total_reviews < 5:
        selected_reviews = sorted_reviews  # ë¦¬ë·°ê°€ 5ê°œ ë¯¸ë§Œì´ë©´ ì „ì²´ ì œê³µ
    else:
        top_reviews = sorted_reviews[:total_reviews // 3]  # ìƒìœ„ 1/3 (ê¸ì •ì )
        mid_reviews = sorted_reviews[total_reviews // 3: 2 * total_reviews // 3]  # ì¤‘ê°„ 1/3 (ë³´í†µ)
        low_reviews = sorted_reviews[2 * total_reviews // 3:]  # í•˜ìœ„ 1/3 (ë¶€ì •ì )

        # ìƒ˜í”Œë§: ìƒìœ„ 2ê°œ, ì¤‘ê°„ 2ê°œ, í•˜ìœ„ 1ê°œ (ì´ 5ê°œ)
        selected_reviews = (
            random.sample(top_reviews, min(2, len(top_reviews))) +
            random.sample(mid_reviews, min(2, len(mid_reviews))) +
            random.sample(low_reviews, min(1, len(low_reviews)))
        )

    # ë¦¬ë·° ê¸¸ì´ ì œí•œ ì ìš©
    review_texts = [
        f"ğŸ¬ **{movie_title}**\n**ì‘ì„±ì:** {row[1]} | **í‰ì :** {row[2]}\n{row[3][:max_length]}..." 
        if len(row[3]) > max_length else f"ğŸ¬ **{movie_title}**\n**ì‘ì„±ì:** {row[1]} | **í‰ì :** {row[2]}\n{row[3]}"
        for row in selected_reviews
    ]

    return "\n\n".join(review_texts)


def generate_ai_response(query, movie_data, reviews):
    """ChatGPT APIë¥¼ ì´ìš©í•´ ì˜í™” ì¶”ì²œ ë° ë¦¬ë·° ìš”ì•½ ìƒì„±"""
    prompt = f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{query}"

    ì•„ë˜ ì˜í™” ë°ì´í„°ì™€ ë¦¬ë·°ë¥¼ ì°¸ê³ í•˜ì—¬, ê°€ì¥ ì ì ˆí•œ ë‹µë³€ì„ ë§Œë“¤ì–´ì¤˜.

    ğŸ¬ **ì˜í™” ì •ë³´**:
    {json.dumps(movie_data, ensure_ascii=False, indent=2)}

    ğŸ“ **ì˜í™” ë¦¬ë·°**:
    {reviews}

    ë‹µë³€ í˜•ì‹:
    - **Markdown ë¬¸ë²•**ì„ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì—¬ì•¼ í•¨.
    - í•„ìš”í•˜ë©´ **ë³¼ë“œì²´**, *ì´íƒ¤ë¦­ì²´*, ë¦¬ìŠ¤íŠ¸, ì œëª©ì„ í™œìš©.
    - ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë‹µë³€ ì œê³µ.
    - í•„ìš”í•˜ë©´ ì˜í™” ì¶”ì²œ, ì¤„ê±°ë¦¬ ìš”ì•½, ë¦¬ë·° ìš”ì•½ ë“±ì„ í¬í•¨.
    - ë‹µë³€ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬.
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content.strip()

@app.post("/chat")
async def search(query_data: QueryModel):
    query = query_data.query
    print(f"ì‚¬ìš©ì ì…ë ¥: {query}")

    try:
        # ğŸ”¹ FAISS ê²€ìƒ‰ (ìƒìœ„ 5ê°œ ì˜í™” ì°¾ê¸°)
        embedding = query_embedding(query)
        distances, indices = index.search(embedding, 5)

        if len(indices[0]) == 0:
            raise HTTPException(status_code=404, detail="ê´€ë ¨ëœ ì˜í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ğŸ”¹ ì˜í™” ì •ë³´ ë° ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘
        relevant_movies = []
        relevant_reviews = []
        for idx in indices[0]:
            if idx >= len(movies):  # ì¸ë±ìŠ¤ ë²”ìœ„ ì´ˆê³¼ ë°©ì§€
                continue
            movie_data = movies[idx].copy()
            movie_data.pop("ì˜í™”í¬ìŠ¤í„°", None)  # í¬ìŠ¤í„° ì œê±°
            relevant_movies.append(movie_data)

            # ğŸ”¹ í•´ë‹¹ ì˜í™”ì˜ ë¦¬ë·° ê°€ì ¸ì˜¤ê¸°
            relevant_reviews.append(get_movie_reviews(movie_data["ì œëª©"]))

        # ğŸ”¹ AIê°€ ìµœì ì˜ ë‹µë³€ ìƒì„±
        response_text = generate_ai_response(query, relevant_movies, relevant_reviews)
        print(response_text)

        return {"response": response_text}

    except Exception as e:
        print("ì—ëŸ¬ ë°œìƒ:", str(e))
        raise HTTPException(status_code=500, detail="ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")



# ğŸ”¹ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (Render ë°°í¬ ì‹œ ìƒíƒœ ì²´í¬ ê°€ëŠ¥)
@app.get("/")
async def root():
    return {"message": "ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!"}


# ğŸ”¹ Render í™˜ê²½ì— ë§ê²Œ ì‹¤í–‰ ì„¤ì •
if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))  # Renderì—ì„œ ìë™ ê°ì§€
    uvicorn.run(app, host="0.0.0.0", port=port)
