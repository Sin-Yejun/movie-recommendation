from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import faiss
import numpy as np
from openai import OpenAI
import json
import os
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import random
from fastapi.responses import StreamingResponse

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì • ì¶”ê°€ (ë³´ì•ˆ ì„¤ì • ê°€ëŠ¥)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

api_key = os.getenv("OPENAI_API_KEY")

# OpenAI API í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key = api_key)

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# FAISS ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
index = faiss.read_index(os.path.join(BASE_DIR, "db/movie_index.faiss"))

# JSON ì˜í™” ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
with open(os.path.join(BASE_DIR, "db/movies.json"), "r", encoding="utf-8") as f:
    movies = json.load(f)

# NumPy ë°°ì—´ë¡œ ì €ì¥ëœ ì˜í™” ë¦¬ë·° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
movie_reviews = np.load(os.path.join(BASE_DIR, "db/movie_reviews.npy"), allow_pickle=True)

class QueryModel(BaseModel):
    query: str

# ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ OpenAI ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
def query_embedding(text):    
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return np.array(response.data[0].embedding, dtype=np.float32).reshape(1, -1)


# ì˜í™” ì œëª©ìœ¼ë¡œ ë¦¬ë·° ê°€ì ¸ì˜¤ê¸° (ì²­í‚¹ ì ìš© + í‰ì  ê· í˜• ìœ ì§€)
def get_movie_reviews(movie_title, max_reviews=5, max_length=300):

    reviews = movie_reviews[movie_reviews[:, 0] == movie_title]

    # í‰ì  ê¸°ì¤€ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
    sorted_reviews = sorted(reviews, key=lambda x: float(x[2]), reverse=True)

    # í‰ì  ê·¸ë£¹ ë‚˜ëˆ„ê¸°
    total_reviews = len(sorted_reviews)
    
    if total_reviews < 5:
        selected_reviews = sorted_reviews  # ë¦¬ë·°ê°€ 5ê°œ ë¯¸ë§Œì´ë©´ ì „ì²´ ì œê³µ
    else:
        top_reviews = sorted_reviews[:total_reviews // 3]  # ìƒìœ„ 1/3 (ê¸ì •ì )
        mid_reviews = sorted_reviews[total_reviews // 3: 2 * total_reviews // 3]  # ì¤‘ê°„ 1/3 (ë³´í†µ)
        low_reviews = sorted_reviews[2 * total_reviews // 3:]  # í•˜ìœ„ 1/3 (ë¶€ì •ì )

        # ìƒ˜í”Œë§: ìƒìœ„ 2ê°œ, ì¤‘ê°„ 2ê°œ, í•˜ìœ„ 1ê°œ (ì´ 5ê°œ)
        selected_reviews = (
            random.sample(top_reviews, min(2, len(top_reviews))) +
            random.sample(mid_reviews, min(2, len(mid_reviews))) +
            random.sample(low_reviews, min(1, len(low_reviews)))
        )

    # ë¦¬ë·° ê¸¸ì´ ì œí•œ ì ìš©
    review_texts = [
        f"ğŸ¬ **{movie_title}**\n**ì‘ì„±ì:** {row[1]} | **í‰ì :** {row[2]}\n{row[3][:max_length]}..." 
        if len(row[3]) > max_length else f"ğŸ¬ **{movie_title}**\n**ì‘ì„±ì:** {row[1]} | **í‰ì :** {row[2]}\n{row[3]}"
        for row in selected_reviews
    ]

    return "\n\n".join(review_texts)

# ChatGPT APIë¥¼ ì´ìš©í•´ ì˜í™” ì¶”ì²œ ë° ë¦¬ë·° ìš”ì•½ ìƒì„±
def generate_ai_response(query, movie_data, reviews):
    prompt = f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{query}"

    ì•„ë˜ ì˜í™” ë°ì´í„°ì™€ ë¦¬ë·°ë¥¼ ì°¸ê³ í•˜ì—¬, ê°€ì¥ ì ì ˆí•œ ë‹µë³€ì„ ë§Œë“¤ì–´ì¤˜.

    ğŸ¬ **ì˜í™” ì •ë³´**:
    {json.dumps(movie_data, ensure_ascii=False, indent=2)}

    ğŸ“ **ì˜í™” ë¦¬ë·°**:
    {reviews}

    ë‹µë³€ í˜•ì‹:
    - Markdown ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì—¬ì•¼ í•¨.
    - í•„ìš”í•˜ë©´ **ë³¼ë“œì²´**, *ì´íƒ¤ë¦­ì²´*, ë¦¬ìŠ¤íŠ¸, ì œëª©ì„ í™œìš©.
    - ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë‹µë³€ ì œê³µ.
    - í•„ìš”í•˜ë©´ ì˜í™” ì¶”ì²œ, ì¤„ê±°ë¦¬ ìš”ì•½, ë¦¬ë·° ìš”ì•½ ë“±ì„ í¬í•¨.
    - ë‹µë³€ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬.
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        stream= True # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
    )

    for chunk in response:
        if chunk.choices[0].delta.content is not None:
            content = chunk.choices[0].delta.content
            content = content.replace("\n","<br>")
            yield f"data: {content}\n\n"
    # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì‹œ ëª…ì‹œì  ì‹ í˜¸ ì¶”ê°€
    yield "data: [DONE]\n\n"

@app.get("/chat")
async def search(query: str):
    print(f"ì‚¬ìš©ì ì…ë ¥: {query}")

    try:
        # FAISS ê²€ìƒ‰ (ìƒìœ„ 5ê°œ ì˜í™” ì°¾ê¸°)
        embedding = query_embedding(query)
        distances, indices = index.search(embedding, 5)

        if len(indices[0]) == 0:
            raise HTTPException(status_code=404, detail="ê´€ë ¨ëœ ì˜í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì˜í™” ì •ë³´ ë° ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘
        relevant_movies = []
        relevant_reviews = []
        for idx in indices[0]:
            if idx >= len(movies):  # ì¸ë±ìŠ¤ ë²”ìœ„ ì´ˆê³¼ ë°©ì§€
                continue
            movie_data = movies[idx].copy()
            movie_data.pop("ì˜í™”í¬ìŠ¤í„°", None)  # í¬ìŠ¤í„° ì œê±°
            relevant_movies.append(movie_data)

            # í•´ë‹¹ ì˜í™”ì˜ ë¦¬ë·° ê°€ì ¸ì˜¤ê¸°
            relevant_reviews.append(get_movie_reviews(movie_data["ì œëª©"]))

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°˜í™˜
        return StreamingResponse(
            generate_ai_response(query, relevant_movies, relevant_reviews),
            media_type="text/event-stream"
        )

    except Exception as e:
        print("ì—ëŸ¬ ë°œìƒ:", str(e))
        raise HTTPException(status_code=500, detail="ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")



# ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (ë°°í¬ ì‹œ ìƒíƒœ ì²´í¬ ê°€ëŠ¥)
@app.get("/")
async def root():
    return {"message": "ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!"}


# ë°°í¬ í™˜ê²½ì— ë§ê²Œ ì‹¤í–‰ ì„¤ì •
if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))  # Renderì—ì„œ ìë™ ê°ì§€
    uvicorn.run(app, host="0.0.0.0", port=port)
